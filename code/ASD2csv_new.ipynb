{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter, OrderedDict\n",
    "from ast import literal_eval\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WindowsPath('asd_result/train/train_vimeo_410316487'), WindowsPath('asd_result/train/train_vimeo_420368971'), WindowsPath('asd_result/train/train_vimeo_429747058'), WindowsPath('asd_result/train/train_vimeo_440357459'), WindowsPath('asd_result/train/train_vimeo_460704945'), WindowsPath('asd_result/train/train_vimeo_471034832'), WindowsPath('asd_result/train/train_vimeo_480532944'), WindowsPath('asd_result/train/train_vimeo_481373806'), WindowsPath('asd_result/train/train_vimeo_491282558'), WindowsPath('asd_result/train/train_vimeo_503562591'), WindowsPath('asd_result/train/train_vimeo_526348428'), WindowsPath('asd_result/train/train_vimeo_543689289'), WindowsPath('asd_result/train/train_vimeo_546221378'), WindowsPath('asd_result/train/train_vimeo_562725349'), WindowsPath('asd_result/train/train_vimeo_611083383'), WindowsPath('asd_result/train/train_vimeo_656699672'), WindowsPath('asd_result/test/test_vimeo_414944373'), WindowsPath('asd_result/test/test_vimeo_425295077'), WindowsPath('asd_result/test/test_vimeo_472545103'), WindowsPath('asd_result/test/test_vimeo_492548673'), WindowsPath('asd_result/test/test_vimeo_563666778'), WindowsPath('asd_result/test/test_vimeo_650895335'), WindowsPath('asd_result/val/val_vimeo_429364395'), WindowsPath('asd_result/val/val_vimeo_451920877'), WindowsPath('asd_result/val/val_vimeo_636257459')]\n"
     ]
    }
   ],
   "source": [
    "folder = [Path(\".\\\\asd_result\\\\train\"),Path(\".\\\\asd_result\\\\test\"), Path(\".\\\\asd_result\\\\val\")]\n",
    "subfolder=[]\n",
    "for i in folder:\n",
    "    temp=[i / f for f in os.listdir(i) if not f.startswith('.') and os.path.isdir(i / f)]\n",
    "    subfolder = subfolder + temp\n",
    "print(subfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just want to test on a single file\n",
    "# subfolder=subfolder[-3:-2]\n",
    "# print(subfolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load ASD result and save to ASDout.csv that is of ['frame', 'scene_id', 'track_id', ASDscore', 'bbox_xmin', 'bbox_y_min', 'bbox_xmax', 'bbox_ymax']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'ASDout.csv'\n",
    "\n",
    "for i in subfolder:\n",
    "    path = i / 'pywork'    \n",
    "    filename=['faces.pckl', 'scene.pckl', 'scores.pckl', 'tracks.pckl']\n",
    "    with open(path / filename[3], 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    with open(path / filename[2], 'rb') as f:\n",
    "        scoredata = pickle.load(f)\n",
    "    with open(path / filename[1], 'rb') as f:\n",
    "        scenedata = pickle.load(f)\n",
    "        \n",
    "    scene_id=[]\n",
    "    for j in range(len(scenedata)):\n",
    "        id = int(str(scenedata[j]).split(\",\")[0].split(\"=\")[-1])\n",
    "        scene_id.append(id) # scene_id is the starting frame of each scene\n",
    "#     print(scene_id)\n",
    "   \n",
    "    d,df=[],[]\n",
    "    scene=-1\n",
    "    for j in range(len(data)):\n",
    "        # if the start frame of a track == the start frame of a scene, the scene_id+=1\n",
    "#         print(\"track:\",i,\"start frame:\",data[i]['track']['frame'][0])\n",
    "        while scene+1 < len(scene_id) and data[j]['track']['frame'][0] >= scene_id[scene+1]:\n",
    "            scene+=1\n",
    "#             print(\"scene is now\", scene)\n",
    "        d.append({'frame':data[j]['track']['frame'], \n",
    "                  'scene_id':scene,\n",
    "                  'track_id':j,\n",
    "                  'ASDscore':np.append(0, scoredata[j]).round(decimals=1), # len(scoredata) = len(data)-1, so add 0 at the head\n",
    "                  'bbox_xmin':data[j]['track']['bbox'][:,0].astype(int), \n",
    "                  'bbox_ymin':data[j]['track']['bbox'][:,1].astype(int), \n",
    "                  'bbox_xmax':data[j]['track']['bbox'][:,2].astype(int),\n",
    "                  'bbox_ymax':data[j]['track']['bbox'][:,3].astype(int)})\n",
    "        df.append(pd.DataFrame(data=d[j]))\n",
    "        \n",
    "    result = pd.concat(df)\n",
    "    result_sort=result.sort_values(by=[\"frame\", \"track_id\"])\n",
    "    result_sort.to_csv(i / output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load ASDout.csv and save to turn.csv [frame, [speaker_id], [listener_id]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'ASDout.csv'\n",
    "output_file = \"turn.csv\"\n",
    "\n",
    "for i in subfolder:\n",
    "    df = pd.read_csv(i / input_file)\n",
    "    # select rows of the same frame\n",
    "    # define turn_speaker = [track_id1, track_id2, ...] for all the track_id whose score>0, or =[] if no track_id has score>0\n",
    "    # make [\"frame\" \"speaker\" \"listener\"] as a new dataframe and save to .csv\n",
    "    frame_id, speaker, listener = [],[],[]\n",
    "    frame_id = list(df['frame'].unique())\n",
    "    spk,lsn = [],[]\n",
    "    for j in range(len(df)):\n",
    "        if j>0 and df['frame'].iloc[j]!=df['frame'].iloc[j-1]:\n",
    "            speaker.append(spk)\n",
    "            listener.append(lsn)\n",
    "            spk,lsn = [],[]\n",
    "        if df['ASDscore'].iloc[j]>0:\n",
    "            spk.append(df['track_id'].iloc[j])\n",
    "        else:\n",
    "            lsn.append(df['track_id'].iloc[j])\n",
    "        if j==len(df)-1:\n",
    "            speaker.append(spk)\n",
    "            listener.append(lsn)\n",
    "    pd.DataFrame({'frame':frame_id, 'speaker':speaker, 'listener':listener}).to_csv(i / output_file, index=False)               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove short silence intervals  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def commonelems(x,y):\n",
    "#     common=[]\n",
    "#     for value in x:\n",
    "#         if value in y:\n",
    "#             common.append(value)\n",
    "#     return common\n",
    "\n",
    "def add2dict(dictionary, key, value):\n",
    "    if key not in dictionary:\n",
    "        dictionary[key] = [value]\n",
    "    elif type(dictionary[key]) == list:\n",
    "        dictionary[key].append(value)\n",
    "    else:\n",
    "        dictionary[key] = [dictionary[key], value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PP1 = True # preprocessing 1, remove short silence intervals\n",
    "PP1_th = 25 # threshold to determine short silence interval\n",
    "# here 25 is 1sec when fps=25, so silence intervals that <1s will be treatedd as short silence\n",
    "input_file = \"turn.csv\"\n",
    "output_file = \"turn_PP1.csv\"\n",
    "\n",
    "if PP1:\n",
    "    for i in subfolder:\n",
    "\n",
    "        df=pd.read_csv(i / input_file)\n",
    "        speaker = df['speaker'].apply(lambda x: literal_eval(str(x))).tolist()\n",
    "        listener = df['listener'].apply(lambda x: literal_eval(str(x))).tolist()\n",
    "        frame_id = df['frame'].tolist()\n",
    "\n",
    "        d_right, d_left={},{}\n",
    "        for j in range(1, len(frame_id)):\n",
    "            right = list(set(speaker[j-1])-set(speaker[j]))\n",
    "            for item in right:\n",
    "                add2dict(d_right, key=item, value=j-1)\n",
    "            left = list(set(speaker[j])-set(speaker[j-1]))\n",
    "            for item in left:\n",
    "                add2dict(d_left, key=item, value=j)\n",
    "            # d_left is {speaker_id:[left endpoint]}, d_right is {speaker_id:[right endpoint]}\n",
    "\n",
    "        d={}\n",
    "        for key in d_right:\n",
    "            if key in d_left:\n",
    "                if d_right[key][0]<d_left[key][0]:\n",
    "                    d[key] = list(zip(d_right[key], d_left[key]))\n",
    "                elif len(d_left[key])>1 and d_right[key][0]<d_left[key][1]:\n",
    "                    d[key] = list(zip(d_right[key], d_left[key][1:]))\n",
    "        # now d is {speaker_id:[(right-endpoint, left-endpoint),(),...]}\n",
    "        # we just need to check the length of each left-right, which is the silence interval, and fill the short ones\n",
    "        for key in d:\n",
    "            for right, left in d[key]:\n",
    "                if left-right-1 < PP1_th:\n",
    "                    for j in range(right+1, left):\n",
    "                        speaker[j]+=[key]\n",
    "                        if key in listener[j]:\n",
    "                            listener[j].remove(key) \n",
    "        df = pd.DataFrame({'frame':frame_id, 'speaker':speaker, 'listener':listener}, dtype = int)\n",
    "        df.to_csv(i / output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove short utterance intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PP2 = True # preprocessing 2, remove short utterance intervals\n",
    "PP2_th = 25 # threshold to determine short utterance interval\n",
    "input_file = \"turn_PP1.csv\"\n",
    "output_file = \"turn_PP2.csv\"\n",
    "\n",
    "if PP2:\n",
    "    for i in subfolder:\n",
    "\n",
    "        df=pd.read_csv(i / input_file)\n",
    "        speaker = df['speaker'].apply(lambda x: literal_eval(str(x))).tolist()\n",
    "        listener = df['listener'].apply(lambda x: literal_eval(str(x))).tolist()\n",
    "        frame_id = df['frame'].tolist()\n",
    "\n",
    "        d_right, d_left={},{}\n",
    "        for j in range(1, len(frame_id)):\n",
    "            right = list(set(speaker[j-1])-set(speaker[j]))\n",
    "            for item in right:\n",
    "                add2dict(d_right, key=item, value=j-1)\n",
    "            left = list(set(speaker[j])-set(speaker[j-1]))\n",
    "            for item in left:\n",
    "                add2dict(d_left, key=item, value=j)\n",
    "            # d_left is {speaker_id:[left endpoint]}, d_right is {speaker_id:[right endpoint]}\n",
    "\n",
    "        d={}\n",
    "        for key in d_right:\n",
    "            if key in d_left:\n",
    "                if d_left[key][0]<=d_right[key][0]:\n",
    "                    d[key] = list(zip(d_left[key], d_right[key]))\n",
    "                elif len(d_right[key])>1 and d_left[key][0]<=d_right[key][1]:\n",
    "                    d[key] = list(zip(d_left[key], d_right[key][1:]))\n",
    "        # now d is {speaker_id:[(left-endpoint, right-endpoint),(),...]}\n",
    "        # we just need to check the length of each right-left, which is the utterance interval, and remove the short ones\n",
    "        for key in d:\n",
    "            for left, right in d[key]:\n",
    "                if right+1-left < PP2_th:\n",
    "                    for j in range(left, right+1):\n",
    "                        if key in speaker[j]:\n",
    "                            speaker[j].remove(key)\n",
    "                        listener[j]+=[key]\n",
    "        df = pd.DataFrame({'frame':frame_id, 'speaker':speaker, 'listener':listener}, dtype = int)\n",
    "        df.to_csv(i / output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get training sample information (x_id, x_frame, y_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish asd_result\\train\\train_vimeo_410316487\n",
      "finish asd_result\\train\\train_vimeo_420368971\n",
      "finish asd_result\\train\\train_vimeo_429747058\n",
      "finish asd_result\\train\\train_vimeo_440357459\n",
      "finish asd_result\\train\\train_vimeo_460704945\n",
      "finish asd_result\\train\\train_vimeo_471034832\n",
      "finish asd_result\\train\\train_vimeo_480532944\n",
      "finish asd_result\\train\\train_vimeo_481373806\n",
      "finish asd_result\\train\\train_vimeo_491282558\n",
      "finish asd_result\\train\\train_vimeo_503562591\n",
      "finish asd_result\\train\\train_vimeo_526348428\n",
      "finish asd_result\\train\\train_vimeo_543689289\n",
      "finish asd_result\\train\\train_vimeo_546221378\n",
      "finish asd_result\\train\\train_vimeo_562725349\n",
      "finish asd_result\\train\\train_vimeo_611083383\n",
      "finish asd_result\\train\\train_vimeo_656699672\n",
      "finish asd_result\\test\\test_vimeo_414944373\n",
      "finish asd_result\\test\\test_vimeo_425295077\n",
      "finish asd_result\\test\\test_vimeo_472545103\n",
      "finish asd_result\\test\\test_vimeo_492548673\n",
      "finish asd_result\\test\\test_vimeo_563666778\n",
      "finish asd_result\\test\\test_vimeo_650895335\n",
      "finish asd_result\\val\\val_vimeo_429364395\n",
      "finish asd_result\\val\\val_vimeo_451920877\n",
      "finish asd_result\\val\\val_vimeo_636257459\n"
     ]
    }
   ],
   "source": [
    "PP3 = True\n",
    "LEN_th_max = 10*25 # here 10*25 means 10 seconds (25fps)\n",
    "LEN_th_min = 25 # the potential sampling range of x before y_start\n",
    "input_file = \"turn_PP2.csv\"\n",
    "output_file = \"turn.json\"\n",
    "# output (x_id, x_start, x_end, y_id, y_start, y_end), which is necessary information for a training sample\n",
    "\n",
    "if PP3:\n",
    "    for i in subfolder:   # find the position of x,y\n",
    "        df=pd.read_csv(i / input_file)\n",
    "        speaker = df['speaker'].apply(lambda x: literal_eval(str(x))).tolist()\n",
    "        listener = df['listener'].apply(lambda x: literal_eval(str(x))).tolist()\n",
    "        frame_id = df['frame'].tolist()\n",
    "#         d = dict(zip(frame_id, zip(speaker, listener))    \n",
    "#         df = pd.DataFrame(speaker, index=frame_id, columns =['speaker_id'])\n",
    "        \n",
    "        d_right, d_left={},{}\n",
    "        for j in range(1, len(frame_id)):\n",
    "            right = list(set(speaker[j-1])-set(speaker[j]))\n",
    "            for item in right:\n",
    "                add2dict(d_right, key=item, value=j-1)\n",
    "            left = list(set(speaker[j])-set(speaker[j-1]))\n",
    "            for item in left:\n",
    "                add2dict(d_left, key=item, value=j)\n",
    "            # d_left is {speaker_id:[left endpoint]}, d_right is {speaker_id:[right endpoint]}\n",
    "                 \n",
    "        d={}\n",
    "        for key in d_right:\n",
    "            if key in d_left:\n",
    "                if d_left[key][0]<=d_right[key][0]:\n",
    "                    d[key] = list(zip(d_left[key], d_right[key]))\n",
    "                elif len(d_right[key])>1 and d_left[key][0]<=d_right[key][1]:\n",
    "                    d[key] = list(zip(d_left[key], d_right[key][1:]))\n",
    "        # now d is {speaker_id:[(left-endpoint, right-endpoint),(),...]}\n",
    "        # we can assign y_id=speaker_id, y_start=left_endpoint, y_end=right_endpoint, \n",
    "        # x_start=left_endpoint-LEN_th, x_end=left_endpoint-1, x_id=listener in [x_start:x_end+1],\n",
    "        training_sample=[]\n",
    "        for key in d:\n",
    "            for left, right in d[key]:\n",
    "                y_id = key\n",
    "                y_start = left # this is index, not frame number, the same below. \n",
    "                y_end = right\n",
    "                x_start = left-LEN_th_max if left-LEN_th_max >= 0 else 0\n",
    "                x_end = left-1 if left-1 >= 0 else 0\n",
    "                x_id = list(set().union(*listener[x_start:x_end+1]))\n",
    "                for x in x_id:\n",
    "                    x_mask = [x in j for j in listener[x_start:x_end+1]]*np.arange(x_start,x_end+1)\n",
    "                    x_frame = x_mask[x_mask!=0]\n",
    "                    x_frame = np.array(frame_id)[x_frame] # convert to frame number\n",
    "                    if len(x_frame) >= LEN_th_min:\n",
    "                        training_sample.append({\"x_id\":x, \"x_frame\":list(map(int, x_frame)), \"y_id\":y_id})\n",
    "                 \n",
    "        with open(i / output_file,'w') as fp:\n",
    "            json.dump(training_sample, fp) \n",
    "        print(\"finish \"+str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check feature availability for each training sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_intersection_over_union(boxA, boxB, evalCol = False):\n",
    "\t# CPU: IOU Function to calculate overlap between two image\n",
    "\txA = max(boxA[0], boxB[0])\n",
    "\tyA = max(boxA[1], boxB[1])\n",
    "\txB = min(boxA[2], boxB[2])\n",
    "\tyB = min(boxA[3], boxB[3])\n",
    "\tinterArea = max(0, xB - xA) * max(0, yB - yA)\n",
    "\tboxAArea = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n",
    "\tboxBArea = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n",
    "\tif evalCol == True:\n",
    "\t\tiou = interArea / float(boxAArea)\n",
    "\telse:\n",
    "\t\tiou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "\treturn iou\n",
    "\n",
    "# combine output (rows) of OpenFace and ActiveSpeakerDetection, only if their detected faces have intersected bounding box, the threshold of IOU is 0.1\n",
    "# ATTENTION: the output exclude frames where IOU<threshold, so the results are probably not continuous, currently we do not require continuous samples for training.\n",
    "def combine(face, asd, x_frame, x_id=None, threshold=0.1, success_only=False):\n",
    "    temp=[]\n",
    "#     asd_dummy = [np.NaN]*len(asd.columns)\n",
    "#     face_dummy = [np.NaN]*len(face.columns)\n",
    "#     print(len(x_frame))\n",
    "#     print(x_frame)\n",
    "    for i in x_frame:\n",
    "        df_face = face.loc[face['frame']==i]\n",
    "        df_asd = asd.loc[asd['frame']==i]\n",
    "        if x_id is not None:\n",
    "            df_asd = df_asd.loc[df_asd['track_id']==x_id]\n",
    "        if success_only:\n",
    "            df_face = df_face.loc[df_face['success']==1]\n",
    "        if (not df_face.empty) and (not df_asd.empty):\n",
    "            # combine df_face and df_asd\n",
    "            IOU = np.empty((len(df_face)*2,len(df_asd)*2)); IOU.fill(threshold)\n",
    "            # *2 is for creating dummy rows and columns, but I am not sure if it's necessary\n",
    "            bboxA = df_face[['xmin', 'ymin', 'xmax', 'ymax']]\n",
    "            bboxB = df_asd[['bbox_xmin', 'bbox_ymin', 'bbox_xmax', 'bbox_ymax']]\n",
    "            for j in range(len(df_face)): # row\n",
    "                IOU[j][:len(df_asd)] = [bb_intersection_over_union(list(bboxA.iloc[j]), list(bboxB.iloc[k])) for k in range(len(df_asd))]\n",
    "            row_ind, col_ind = linear_sum_assignment(-IOU)\n",
    "            # row_ind, col_ind are something like [0,1,2] [1,2,0], where it means 0th of df_face paired with 1th of df_asd, 1th with 2th, and 2th with 0th\n",
    "            # in other words, idx=0, 0--1, idx=1, 1--2, idx=2, 2--0\n",
    "            # then we want to choose from above pairs, if the left--right satisfies left<len(df_face) and right<len(df_asd) (i.e. both left and right are not dummy)   \n",
    "            # combine df_face and df_asd by row_ind, col_ind\n",
    "            idx=0  \n",
    "            for j in range(max(len(df_asd),len(df_face))): \n",
    "                if idx < len(col_ind) and col_ind[idx] < len(df_asd) and idx < len(row_ind) and row_ind[idx] < len(df_face):\n",
    "                    left = list(df_asd.iloc[col_ind[idx]])\n",
    "                    right = list(df_face.iloc[row_ind[idx]])\n",
    "                    temp.append(left + right[1:])                \n",
    "                idx+=1\n",
    "#     print(\"len %d -> %d\" % (len(x_frame), len(temp)))  \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder2 = [Path(\".\\\\openface_data\\\\openface_features\\\\train\"),Path(\".\\\\openface_data\\\\openface_features\\\\test\"),Path(\".\\\\openface_data\\\\openface_features\\\\val\")]\n",
    "subfolder2 = []\n",
    "for i in folder2:\n",
    "    temp=[i / f for f in os.listdir(i) if not f.startswith('.') and os.path.isdir(i / f)]\n",
    "    subfolder2 = subfolder2 + temp\n",
    "# assert len(subfolder)==len(subfolder2)\n",
    "\n",
    "# just want to test on a single file\n",
    "# subfolder2=subfolder2[-3:-2]\n",
    "# print(subfolder2)\n",
    "\n",
    "cbfolder=[]\n",
    "for i in range(len(subfolder)):\n",
    "    assert str(subfolder[i])[-9:]==str(subfolder2[i])[-9:]\n",
    "    cbfolder.append((subfolder[i],subfolder2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asd_result\\train\\train_vimeo_410316487 openface_data\\openface_features\\train\\train_vimeo_410316487\n",
      "finish asd_result\\train\\train_vimeo_410316487\n",
      "asd_result\\train\\train_vimeo_420368971 openface_data\\openface_features\\train\\train_vimeo_420368971\n",
      "finish asd_result\\train\\train_vimeo_420368971\n",
      "asd_result\\train\\train_vimeo_429747058 openface_data\\openface_features\\train\\train_vimeo_429747058\n",
      "finish asd_result\\train\\train_vimeo_429747058\n",
      "asd_result\\train\\train_vimeo_440357459 openface_data\\openface_features\\train\\train_vimeo_440357459\n",
      "finish asd_result\\train\\train_vimeo_440357459\n",
      "asd_result\\train\\train_vimeo_460704945 openface_data\\openface_features\\train\\train_vimeo_460704945\n",
      "finish asd_result\\train\\train_vimeo_460704945\n",
      "asd_result\\train\\train_vimeo_471034832 openface_data\\openface_features\\train\\train_vimeo_471034832\n",
      "finish asd_result\\train\\train_vimeo_471034832\n",
      "asd_result\\train\\train_vimeo_480532944 openface_data\\openface_features\\train\\train_vimeo_480532944\n",
      "finish asd_result\\train\\train_vimeo_480532944\n",
      "asd_result\\train\\train_vimeo_481373806 openface_data\\openface_features\\train\\train_vimeo_481373806\n",
      "finish asd_result\\train\\train_vimeo_481373806\n",
      "asd_result\\train\\train_vimeo_491282558 openface_data\\openface_features\\train\\train_vimeo_491282558\n",
      "finish asd_result\\train\\train_vimeo_491282558\n",
      "asd_result\\train\\train_vimeo_503562591 openface_data\\openface_features\\train\\train_vimeo_503562591\n",
      "finish asd_result\\train\\train_vimeo_503562591\n",
      "asd_result\\train\\train_vimeo_526348428 openface_data\\openface_features\\train\\train_vimeo_526348428\n",
      "finish asd_result\\train\\train_vimeo_526348428\n",
      "asd_result\\train\\train_vimeo_543689289 openface_data\\openface_features\\train\\train_vimeo_543689289\n",
      "finish asd_result\\train\\train_vimeo_543689289\n",
      "asd_result\\train\\train_vimeo_546221378 openface_data\\openface_features\\train\\train_vimeo_546221378\n",
      "finish asd_result\\train\\train_vimeo_546221378\n",
      "asd_result\\train\\train_vimeo_562725349 openface_data\\openface_features\\train\\train_vimeo_562725349\n",
      "finish asd_result\\train\\train_vimeo_562725349\n",
      "asd_result\\train\\train_vimeo_611083383 openface_data\\openface_features\\train\\train_vimeo_611083383\n",
      "finish asd_result\\train\\train_vimeo_611083383\n",
      "asd_result\\train\\train_vimeo_656699672 openface_data\\openface_features\\train\\train_vimeo_656699672\n",
      "finish asd_result\\train\\train_vimeo_656699672\n",
      "asd_result\\test\\test_vimeo_414944373 openface_data\\openface_features\\test\\414944373\n",
      "finish asd_result\\test\\test_vimeo_414944373\n",
      "asd_result\\test\\test_vimeo_425295077 openface_data\\openface_features\\test\\425295077\n",
      "finish asd_result\\test\\test_vimeo_425295077\n",
      "asd_result\\test\\test_vimeo_472545103 openface_data\\openface_features\\test\\472545103\n",
      "finish asd_result\\test\\test_vimeo_472545103\n",
      "asd_result\\test\\test_vimeo_492548673 openface_data\\openface_features\\test\\492548673\n",
      "finish asd_result\\test\\test_vimeo_492548673\n",
      "asd_result\\test\\test_vimeo_563666778 openface_data\\openface_features\\test\\563666778\n",
      "finish asd_result\\test\\test_vimeo_563666778\n",
      "asd_result\\test\\test_vimeo_650895335 openface_data\\openface_features\\test\\650895335\n",
      "finish asd_result\\test\\test_vimeo_650895335\n",
      "asd_result\\val\\val_vimeo_429364395 openface_data\\openface_features\\val\\429364395\n",
      "finish asd_result\\val\\val_vimeo_429364395\n",
      "asd_result\\val\\val_vimeo_451920877 openface_data\\openface_features\\val\\451920877\n",
      "finish asd_result\\val\\val_vimeo_451920877\n",
      "asd_result\\val\\val_vimeo_636257459 openface_data\\openface_features\\val\\636257459\n",
      "finish asd_result\\val\\val_vimeo_636257459\n"
     ]
    }
   ],
   "source": [
    "# very slow\n",
    "PP4 = True\n",
    "input_file = \"turn.json\"\n",
    "output_file = \"training_sample_detail.json\"\n",
    "asd_file = \"ASDout.csv\"\n",
    "data_folder = \"data1\"\n",
    "# output (x_id, x_start, x_end, y_id, y_start, y_end), which is necessary information for a training sample\n",
    "\n",
    "basic = ['frame','face_id','success']\n",
    "gaze_direction = ['gaze_angle_x','gaze_angle_y']\n",
    "# head_position = ['pose_Tx', 'pose_Ty', 'pose_Tz', 'pose_Rx', 'pose_Ry', 'pose_Rz'] # first three can be removed\n",
    "face_landmark2d = [] # this can be removed\n",
    "for i in range(0,68):\n",
    "    face_landmark2d.append(\"x_\"+str(i))\n",
    "for i in range(0,68):\n",
    "    face_landmark2d.append(\"y_\"+str(i))\n",
    "PDM_rigid = ['p_scale', 'p_rx', 'p_ry', 'p_rz', 'p_tx', 'p_ty'] # can be removed\n",
    "PDM_nonrigid = []\n",
    "for i in range(0,34): # can be removed\n",
    "    PDM_nonrigid.append(\"p_\"+str(i))\n",
    "FAU = ['AU01_r', 'AU02_r', 'AU04_r', 'AU05_r', 'AU06_r', 'AU07_r', 'AU09_r', 'AU10_r', 'AU12_r', 'AU14_r', 'AU15_r', 'AU17_r', 'AU20_r', 'AU23_r', 'AU25_r', 'AU26_r', 'AU45_r']\n",
    "col_list = basic + gaze_direction + face_landmark2d + PDM_rigid + PDM_nonrigid + FAU\n",
    "output_col = ['frame']+col_list[3:]\n",
    "    \n",
    "if PP4:\n",
    "    for i,j in cbfolder:\n",
    "        print(i,j)\n",
    "        stat=[]\n",
    "        face = pd.read_csv(j / (j.name+'.csv'), usecols=col_list)     \n",
    "        \n",
    "        x1,x2,y1,y2=face.columns.get_loc(\"x_0\"),face.columns.get_loc(\"x_67\"),face.columns.get_loc(\"y_0\"),face.columns.get_loc(\"y_67\")\n",
    "        xmin,xmax,ymin,ymax=np.min(face.iloc[:,x1:x2],axis=1),np.max(face.iloc[:,x1:x2],axis=1),np.min(face.iloc[:,y1:y2],axis=1),np.max(face.iloc[:,y1:y2],axis=1)\n",
    "        face['xmin'], face['ymin'], face['xmax'], face['ymax'] = [xmin,ymin,xmax,ymax]\n",
    "        \n",
    "        asd = pd.read_csv(i / asd_file)\n",
    "        \n",
    "        columns = list(asd.columns)+list(face.columns)[1:] \n",
    "        ind = [columns.index(i) for i in output_col]\n",
    "        \n",
    "        with open(i / input_file, \"r\") as fp:\n",
    "            samples = json.load(fp)  # [x_id, x_frame, y_id], id is related to ASD \n",
    "                   \n",
    "        Path(i / data_folder).mkdir(exist_ok=True)\n",
    "        for k in range(len(samples)):\n",
    "#         for k in range(1):\n",
    "            x_id, x_frame, y_id = samples[k][\"x_id\"], samples[k][\"x_frame\"], samples[k][\"y_id\"]\n",
    "            result = np.array(combine(face, asd, x_frame, x_id=x_id))\n",
    "            if result.size>0:              \n",
    "#                 print(result[:10,:])\n",
    "#                 break\n",
    "                stat.append({\"filename\":\"data_\"+str(k), \"x_id\":x_id, \"y_id\":y_id, \n",
    "                        \"x_frame\":result[:,0].tolist(), \"x_pos\":result[:,4:8].tolist()})\n",
    "                data = np.float32(result[:,ind])\n",
    "                output=(x_id, y_id, data)\n",
    "                with open(i / data_folder / (\"data_\"+str(k)), \"wb\") as fp:\n",
    "                    pickle.dump(output, fp)\n",
    "        with open(i / output_file, 'w') as fp:\n",
    "            json.dump(stat, fp)      \n",
    "        print(\"finish \"+str(i))      \n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
